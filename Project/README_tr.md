 Projectverhaal â€“ Van Directe Taxigegevens naar Inzicht


â± Duur: 2 weken


 Team: Yasin (Teamleider), Kahraman, Emine, AyÅŸe


ğŸ”§ Tools: Microsoft Fabric | Eventstream | Delta Lake | Dataflow Gen2 | Power BI | Eventhouse | Activator | Trello

## Azure DP-700 Projesi
Bu projede amacÄ±m, Microsoft Fabric DP-700 sÄ±navÄ± kapsamÄ±nda gerÃ§ek hayata uygun veri mÃ¼hendisliÄŸi becerilerimi gÃ¶stermekti. Projede:

Verilerin toplanmasÄ±, yÃ¼klenmesi ve dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi (batch & streaming),

SQL, PySpark ve KQL ile veri dÃ¶nÃ¼ÅŸÃ¼mleri,

Lakehouse ve Data Warehouse gibi veri mimarisi tasarÄ±mlarÄ±,

GÃ¼venlik, eriÅŸim kontrolleri ve veri yÃ¶netiÅŸimi,

Pipelineâ€™lar ve tetikleyicilerle otomasyon,

Performans izleme ve optimizasyon
konularÄ±nda Ã§alÄ±ÅŸtÄ±m.

Bu projeyle veri mÃ¼hendisliÄŸi yetkinliklerimi ve Azure/Microsoft Fabric ortamÄ±nda Ã§Ã¶zÃ¼m geliÅŸtirme becerilerimi sergilemeyi hedefledim.


## Proje Diyagrami
Ã–nce projemize diyagram Ã§izerek baÅŸladÄ±k. BÃ¶ylece projede yapmamÄ±z gerekenleri gorselleÅŸtirerek izleyecegimiz adÄ±mlarÄ± daha net gÃ¶rebildik.
![diyagram](./images/diyagram.png)

## GÃ¶rev paylaÅŸÄ±mÄ±

Team liderliÄŸini yaptÄ±ÄŸÄ±m bu projede trello ile gÃ¶rev daÄŸÄ±lÄ±mlarÄ± yaptÄ±m ve sprintler oluÅŸturdum. BÃ¶ylece projemizi zamanÄ±nda teslim edebildik.
![trello](./images/trello.png)


##  Stap 1: Ruwe data realtime ontvangen via Eventstream

Projemize, taksilerden gelen veriyi gerÃ§ek zamanlÄ± olarak alarak baÅŸladÄ±k. Her taksi bir olay (event) oluÅŸturduÄŸunda â€” Ã¶rneÄŸin bir yolculuk baÅŸladÄ±ÄŸÄ±nda veya bittiÄŸinde â€” bu veri anÄ±nda Eventstream Ã¼zerinden sistemimize aktarÄ±ldÄ±.

![get data](./images/get_eventdata.png)

Bu veriler doÄŸrudan herhangi bir iÅŸlem yapÄ±lmadan Delta Lake'in Bronze katmanÄ±na kaydedildi. BÃ¶ylece elimizde her ÅŸeyin en ham haliyle tutulduÄŸu bir veri deposu oluÅŸtu.

## Stap 2: Opschonen en transformeren met Pyspark
Ham verileri Silver katmanÄ±na geÃ§meden Ã¶nce temizlememiz gerekiyordu. Bunun iÃ§in Notebook da Pyspark  aracÄ±nÄ± kullandÄ±k.
![payspark](./images/pyspark.png)

Bu aÅŸamada:

GeÃ§ersiz/veri eksikliÄŸi olan kayÄ±tlarÄ± ayÄ±kladÄ±k,

Tarih ve saat formatlarÄ±nÄ± dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼k,

KullanÄ±m amacÄ±na uygun sÃ¼tunlarÄ± hazÄ±rladÄ±k.

## Stap 3: Modelleren in Gold met Star Schema
Silver katmandan gelen dÃ¼zenlenmiÅŸ verileri, Dataflow Gen2 kullanarak Gold katmanda birleÅŸtirdik ve analiz ile raporlamaya hazÄ±r hale getirdik.
Burada dimension ve fact tablolarÄ± oluÅŸturduk â€” Ã¶rneÄŸin:

![tables](./images/fact-dim-tables.png)

dim_date2, dim_location, dÄ±m_vendor fact_trim

![schema](./images/star-schema.png)

Bu modelleme sayesinde performanslÄ± ve filtrelenebilir raporlar oluÅŸturabildik.

## Stap 4: Analyse & visualisatie in Power BI
Gold katmandaki verileri Power BI ile baÄŸlayarak, kullanÄ±ÅŸlÄ± ve ÅŸÄ±k bir dashboard tasarladÄ±k.

![1](./images/chart1.png) ![2](./images/chart2.png) ![3](./images/chart3.png)

Dashboard Ã¶zellikleri:

Tarih, lokasyon ve taksi bazlÄ± filtreler

Toplam rit, ortalama mesafe, en yoÄŸun saatler gibi KPIs

Harita gÃ¶rselleÅŸtirmeleri ile lokasyon bazlÄ± analiz

## Stap 5: Realtime monitoring met Eventhouse
Veri akÄ±ÅŸÄ±nÄ±n dÃ¼zgÃ¼n ilerleyip ilerlemediÄŸini anlÄ±k gÃ¶rmek iÃ§in Eventhouse kullandÄ±k.

[dashboard1](./images/realtime-dashboard1.png) [dashboard2](./images/realtime-dashboard2.png)


 Burada:

CanlÄ± event akÄ±ÅŸlarÄ±nÄ± takip ettik,

Gecikme ya da veri kaybÄ± gibi problemleri Ã¶nceden fark ettik.

## Stap 6: Automatisering met Activator
Veri geldiÄŸinde bazÄ± tetikleyici (trigger) iÅŸlemler gerÃ§ekleÅŸtirmek istedik. Bunun iÃ§in Activator kurduk.
Ã–rneÄŸin:

Belirli bir taksi bir saatte 5â€™ten fazla yolculuk yaparsa tetikleyici mesaj oluÅŸturma

Gece saatlerinde uzun mesafeli yolculuklarÄ± ayrÄ± izleme

Bu sayede sadece raporlama deÄŸil, proaktif veri reaksiyonlarÄ± da geliÅŸtirdik.

